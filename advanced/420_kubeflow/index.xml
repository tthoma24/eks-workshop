<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning using Kubeflow on Amazon EKS Workshop</title><link>/advanced/420_kubeflow/</link><description>Recent content in Machine Learning using Kubeflow on Amazon EKS Workshop</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 15 Nov 2019 00:00:00 -0800</lastBuildDate><atom:link href="/advanced/420_kubeflow/index.xml" rel="self" type="application/rss+xml"/><item><title>Install</title><link>/advanced/420_kubeflow/install/</link><pubDate>Thu, 22 Aug 2019 00:00:00 -0800</pubDate><guid>/advanced/420_kubeflow/install/</guid><description>In this chapter, we will install Kubeflow on Amazon EKS cluster. If you don&amp;rsquo;t have an EKS cluster, please follow instructions from getting started guide and then launch your EKS cluster using eksctl chapter
Increase cluster size We need more resources for completing the Kubeflow chapter of the EKS Workshop. First, we&amp;rsquo;ll increase the size of our cluster to 6 nodes:
export NODEGROUP_NAME=$(eksctl get nodegroups --cluster eksworkshop-eksctl -o json | jq -r '.</description></item><item><title>Kubeflow Dashboard</title><link>/advanced/420_kubeflow/dashboard/</link><pubDate>Thu, 22 Aug 2019 00:00:00 -0800</pubDate><guid>/advanced/420_kubeflow/dashboard/</guid><description>Kubeflow Dashboard Get Kubeflow service endpoint:
kubectl get ingress -n istio-system -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}' Access the endpoint address in a browser to see Kubeflow dashboard. It could take couple of minutes for Load Balancer to launch and health checks to pass
Click on Start Setup
Specify the namespace as eksworkshop
Click on Finish to view the dashboard</description></item><item><title>Jupyter Notebook</title><link>/advanced/420_kubeflow/jupyter/</link><pubDate>Mon, 26 Aug 2019 00:00:00 -0800</pubDate><guid>/advanced/420_kubeflow/jupyter/</guid><description>Jupyter Notebook using Kubeflow on Amazon EKS The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. It is often used for data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and more.
In Kubeflow dashboard, click on Create a new Notebook server:
Select the namespace created in previous step:
This pre-populates the namespace field on the dashboard.</description></item><item><title>Model training</title><link>/advanced/420_kubeflow/training/</link><pubDate>Tue, 27 Aug 2019 00:00:00 -0800</pubDate><guid>/advanced/420_kubeflow/training/</guid><description>Model Training While Jupyter notebook is good for interactive model training, you may like to package the training code as Docker image and run it in Amazon EKS cluster.
This chapter explains how to build a training model for Fashion-MNIST dataset using TensorFlow and Keras on Amazon EKS. This dataset contains 70,000 grayscale images in 10 categories and is meant to be a drop-in replace of MNIST.
Docker image We will use a pre-built Docker image seedjeffwan/mnist_tensorflow_keras:1.</description></item><item><title>Model inference</title><link>/advanced/420_kubeflow/inference/</link><pubDate>Tue, 27 Aug 2019 00:00:00 -0800</pubDate><guid>/advanced/420_kubeflow/inference/</guid><description>Model Inference After the model is trained and stored in S3 bucket, the next step is to use that model for inference.
This chapter explains how to use the previously trained model and run inference using TensorFlow and Keras on Amazon EKS.
Run inference pod A model from training was stored in the S3 bucket in previous section. Make sure S3_BUCKET and AWS_REGION environment variables are set correctly.
curl -LO https://eksworkshop.</description></item><item><title>Fairing</title><link>/advanced/420_kubeflow/fairing/</link><pubDate>Wed, 13 Nov 2019 21:55:32 -0500</pubDate><guid>/advanced/420_kubeflow/fairing/</guid><description>Kubeflow Fairing Jupyter notebooks are a great way to author your model creation. You can write the algorithms, train the model and if you need a way to publish the inference endpoint directly from this interface, you can use Kubeflow fairing to do so
Assign ECR permissions For this chapter, we will create a training image and store it in ECR. We need to add an IAM policy to Worker nodes so that we can write to ECR.</description></item><item><title>Kubeflow pipeline</title><link>/advanced/420_kubeflow/pipelines/</link><pubDate>Tue, 27 Aug 2019 00:00:00 -0800</pubDate><guid>/advanced/420_kubeflow/pipelines/</guid><description>Kubeflow Pipelines Kubeflow Pipeline is one the core components of the toolkit and gets deployed automatically when you install Kubeflow. Kubeflow Pipelines consists of:
A user interface (UI) for managing and tracking experiments, jobs, and runs. An engine for scheduling multi-step ML workflows. An SDK for defining and manipulating pipelines and components. Notebooks for interacting with the system using the SDK. Amazon Sagemaker is a managed service that enables data scientists and developers to quickly and easily build, train, and deploy machine learning models.</description></item><item><title>Kubeflow Distributed Training</title><link>/advanced/420_kubeflow/distributed/</link><pubDate>Fri, 15 Nov 2019 00:00:00 -0800</pubDate><guid>/advanced/420_kubeflow/distributed/</guid><description>Distributed Training using tf-operator and pytorch-operator TFJob is a Kubernetes custom resource that you can use to run TensorFlow training jobs on Kubernetes. The Kubeflow implementation of TFJob is in tf-operator. Similarly, you can create PyTorch Job by defining a PyTorchJob config file and pytorch-operator will help create PyTorch job, monitor and keep track of the job.
Go to your eks-kubeflow-workshop notebook server and browse for distributed training notebooks (eks-workshop-notebook/notebooks/03_Distributed_Training/03_01_Distributed_Training_ParameterServer.ipynb). If you havenâ€™t installed notebook server, review fairing chapter and finish the clone the repo instructions.</description></item><item><title>Cleanup</title><link>/advanced/420_kubeflow/cleanup/</link><pubDate>Fri, 25 Oct 2019 15:43:24 -0400</pubDate><guid>/advanced/420_kubeflow/cleanup/</guid><description>Uninstall Kubeflow Delete IAM users, S3 bucket and Kubernetes secret
# delete s3user aws iam detach-user-policy --user-name s3user --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess aws iam delete-access-key --access-key-id `echo $AWS_ACCESS_KEY_ID_VALUE | base64 --decode` --user-name s3user aws iam delete-user --user-name s3user # delete sagemakeruser aws iam detach-user-policy --user-name sagemakeruser --policy-arn arn:aws:iam::aws:policy/AmazonSageMakerFullAccess aws iam delete-access-key --access-key-id `echo $AWS_ACCESS_KEY_ID_VALUE | base64 --decode` --user-name sagemakeruser aws iam delete-user --user-name sagemakeruser # delete S3 bucket aws s3 rb s3://$S3_BUCKET --force --region $AWS_REGION # delete aws-secret kubectl delete secret/aws-secret kubectl delete secret/aws-secret -n kubeflow Run these commands to uninstall Kubeflow from your EKS cluster</description></item></channel></rss>