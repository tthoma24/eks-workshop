<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CON205 on Amazon EKS Workshop</title><link>/tags/con205/</link><description>Recent content in CON205 on Amazon EKS Workshop</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 18 Nov 2018 00:00:00 -0500</lastBuildDate><atom:link href="/tags/con205/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction</title><link>/010_introduction/</link><pubDate>Wed, 03 Oct 2018 10:23:24 -0700</pubDate><guid>/010_introduction/</guid><description>Introduction to Kubernetes A walkthrough of basic Kubernetes concepts.
Welcome to the Amazon EKS Workshop!
The intent of this workshop is to educate users about the features of Amazon EKS.
Background in EKS, Kubernetes, Docker, and container workflows are not required, but they are recommended.
This chapter will introduce you to the basic workings of Kubernetes, laying the foundation for the hands-on portion of the workshop.
Specifically, we will walk you through the following topics:</description></item><item><title>Start the workshop...</title><link>/020_prerequisites/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/020_prerequisites/</guid><description>Getting Started To start the workshop, follow one of the following depending on whether you are&amp;hellip;
&amp;hellip;running the workshop on your own (in your own account), or &amp;hellip;attending an AWS hosted event (using AWS provided hashes) Once you have completed with either setup, continue with Create a Workspace</description></item><item><title>Launch using eksctl</title><link>/030_eksctl/</link><pubDate>Tue, 07 Aug 2018 13:36:57 -0700</pubDate><guid>/030_eksctl/</guid><description>Launch using eksctl eksctl is a tool jointly developed by AWS and Weaveworks that automates much of the experience of creating EKS clusters.
In this module, we will use eksctl to launch and configure our EKS cluster and nodes.</description></item><item><title>Helm</title><link>/beginner/060_helm/</link><pubDate>Tue, 07 Aug 2018 08:30:11 -0700</pubDate><guid>/beginner/060_helm/</guid><description>Helm This tutorial has been updated for Helm v3. In version 3, the Tiller component was removed, which simplified operations and improved security.
Helm is a package manager for Kubernetes that packages multiple Kubernetes resources into a single logical deployment unit called a Chart. Charts are easy to create, version, share, and publish.
In this chapter, we&amp;rsquo;ll cover installing Helm. Once installed, we&amp;rsquo;ll demonstrate how Helm can be used to deploy a simple nginx webserver, and a more sophisticated microservice.</description></item><item><title>Autoscaling our Applications and Clusters</title><link>/beginner/080_scaling/</link><pubDate>Tue, 07 Aug 2018 08:30:11 -0700</pubDate><guid>/beginner/080_scaling/</guid><description>Implement AutoScaling with HPA and CA In this Chapter, we will show patterns for scaling your worker nodes and applications deployments automatically. Automatic scaling in K8s comes in two forms:
Horizontal Pod Autoscaler (HPA) scales the pods in a deployment or replica set. It is implemented as a K8s API resource and a controller. The controller manager queries the resource utilization against the metrics specified in each HorizontalPodAutoscaler definition.</description></item><item><title>Intro to RBAC</title><link>/beginner/090_rbac/</link><pubDate>Wed, 03 Oct 2018 10:14:46 -0700</pubDate><guid>/beginner/090_rbac/</guid><description>Intro to RBAC In this chapter, we&amp;rsquo;ll learn about how role based access control (RBAC) works in kubernetes.</description></item><item><title>IAM Roles for Service Accounts</title><link>/beginner/110_irsa/</link><pubDate>Tue, 13 Nov 2018 16:32:30 +0900</pubDate><guid>/beginner/110_irsa/</guid><description>Fine-Grained IAM Roles for Service Accounts In Kubernetes version 1.12, support was added for a new ProjectedServiceAccountToken feature, which is an OIDC JSON web token that also contains the service account identity, and supports a configurable audience.
Amazon EKS now hosts a public OIDC discovery endpoint per cluster containing the signing keys for the ProjectedServiceAccountToken JSON web tokens so external systems, like IAM, can validate and accept the Kubernetes-issued OIDC tokens.</description></item><item><title>CI/CD with CodePipeline</title><link>/intermediate/220_codepipeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/intermediate/220_codepipeline/</guid><description>CI/CD with CodePipeline Continuous integration (CI) and continuous delivery (CD) are essential for deft organizations. Teams are more productive when they can make discrete changes frequently, release those changes programmatically and deliver updates without disruption.
In this module, we will build a CI/CD pipeline using AWS CodePipeline. The CI/CD pipeline will deploy a sample Kubernetes service, we will make a change to the GitHub repository and observe the automated delivery of this change to the cluster.</description></item><item><title>Tracing with X-Ray</title><link>/intermediate/245_x-ray/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/intermediate/245_x-ray/</guid><description>Tracing with X-Ray As distributed systems evolve, monitoring and debugging services becomes challenging. Container-orchestration platforms like Kubernetes solve a lot of problems, but they also introduce new challenges for developers and operators in understanding how services interact and where latency exists. AWS X-Ray helps developers analyze and debug distributed services.
In this module, we are going to deploy the X-Ray agent as a DaemonSet, deploy sample front-end and back-end services that are instrumented with the X-Ray SDK, make some sample requests and then examine the traces and service maps in the AWS Management Console.</description></item><item><title>Batch Processing with Argo Workflow</title><link>/advanced/410_batch/</link><pubDate>Sun, 18 Nov 2018 00:00:00 -0500</pubDate><guid>/advanced/410_batch/</guid><description>Batch Processing In this Chapter, we will deploy common batch processing scenarios using Kubernetes and Argo.
What is Argo? Argo is an open source container-native workflow engine for getting work done on Kubernetes. Argo is implemented as a Kubernetes CRD (Custom Resource Definition).
Define workflows where each step in the workflow is a container. Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a graph (DAG).</description></item></channel></rss>